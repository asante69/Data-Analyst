{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 11425684,
          "sourceType": "datasetVersion",
          "datasetId": 7155877
        },
        {
          "sourceId": 11438339,
          "sourceType": "datasetVersion",
          "datasetId": 7164960
        }
      ],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asante69/Data-Analyst/blob/main/gen_ai_cv_tailoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core Idea:\n",
        "Take a user's base CV (text) and a job posting URL. Extract relevant information from both. Use generative AI to rewrite/update sections of the CV (like the summary, skills, or specific experience points) to better align with the job description's requirements and keywords.\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-15T17:24:23.774401Z",
          "iopub.execute_input": "2025-04-15T17:24:23.775338Z",
          "iopub.status.idle": "2025-04-15T17:24:23.784688Z",
          "shell.execute_reply.started": "2025-04-15T17:24:23.775301Z",
          "shell.execute_reply": "2025-04-15T17:24:23.7834Z"
        },
        "id": "Ga8x1St6m75W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Potential Generative AI Capabilities to Showcase:\n",
        "- Structured Output / JSON Mode: We'll ask the model to extract key information from the job description and return it in a structured JSON format. This is highly practical for parsing.\n",
        "\n",
        "- Few-Shot Prompting: When generating the tailored CV summary, we'll provide the model with 1 or 2 examples (shots) of how a generic summary can be transformed into a tailored one based on sample job details. This guides the model to produce better, more relevant output.\n",
        "\n",
        "- Document Understanding: This is inherent in the task. The model needs to read and comprehend both the CV (Document 1) and the Job Description (Document 2) to perform the tailoring. We will explicitly call this out and design prompts that require comparison and synthesis of information from both sources, such as the skill matching step.\n",
        "\n",
        "- Information Extraction: Using an LLM to parse the job description and extract key requirements, skills, responsibilities, and company values.\n",
        "\n",
        "- Text Summarization: Summarizing the core requirements of the job description or summarizing the candidate's relevant experience.\n",
        "\n",
        "- Text Generation/Rewriting: Generating a new tailored CV summary or objective statement based on the job description. Rewriting experience bullet points to use keywords from the job posting.\n",
        "\n",
        "- Skill Mapping/Gap Analysis: Identifying skills mentioned in the job description that are present or missing from the CV, potentially suggesting ways to phrase existing experience to cover gaps.\n",
        "\n",
        "- Question Answering (applied): Framing the task as \"How should I update my CV summary for this job?\" and having the model generate an answer (the new summary).\n"
      ],
      "metadata": {
        "id": "BsrHu-rSm75X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob # To find files matching a pattern\n",
        "\n",
        "print(\"Attempting to clean up previous output files...\")\n",
        "\n",
        "# Define the directory where files are saved (usually /kaggle/working/)\n",
        "output_dir = \"/kaggle/working/\"\n",
        "\n",
        "# List of file patterns to delete\n",
        "patterns_to_delete = [\n",
        "    \"updated_cv*.pdf\",\n",
        "    \"updated_cv*.tex\",\n",
        "    \"updated_cv*.log\",\n",
        "    \"llm_raw_output*.tex\",\n",
        "    \"*.aux\",\n",
        "    \"updated_cv*.out\"\n",
        "    # Add any other file patterns you generate\n",
        "]\n",
        "\n",
        "files_deleted_count = 0\n",
        "for pattern in patterns_to_delete:\n",
        "    # Find all files matching the pattern in the output directory\n",
        "    files_to_remove = glob.glob(os.path.join(output_dir, pattern))\n",
        "    for file_path in files_to_remove:\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.remove(file_path)\n",
        "                print(f\"Deleted file: {file_path}\")\n",
        "                files_deleted_count += 1\n",
        "            # Optional: Delete directories if needed (USE WITH CAUTION)\n",
        "            # elif os.path.isdir(file_path):\n",
        "            #     shutil.rmtree(file_path)\n",
        "            #     print(f\"Deleted directory: {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "if files_deleted_count == 0:\n",
        "     print(\"No matching files found to delete in /kaggle/working/\")\n",
        "else:\n",
        "     print(f\"Finished cleaning up {files_deleted_count} previous output file(s).\")\n",
        "\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:01:03.360538Z",
          "iopub.execute_input": "2025-04-20T18:01:03.361131Z",
          "iopub.status.idle": "2025-04-20T18:01:03.371142Z",
          "shell.execute_reply.started": "2025-04-20T18:01:03.361102Z",
          "shell.execute_reply": "2025-04-20T18:01:03.370213Z"
        },
        "id": "0QLE8zOYm75Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries"
      ],
      "metadata": {
        "id": "buVRfr1Jm75Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- transformers, torch, accelerate, bitsandbytes: Core Hugging Face libraries for loading and running models efficiently (bitsandbytes helps with quantization for loading larger models).\n",
        "\n",
        "- langchain: A popular framework for building applications with LLMs (optional but helpful for structuring prompts and chains, especially for an agent approach).\n",
        "\n",
        "- beautifulsoup4, requests: Standard Python libraries for fetching and parsing HTML content from URLs.\n",
        "\n",
        "- sentence_transformers: Can be used for comparing semantic similarity between CV skills and job requirements.\n",
        "\n",
        "- pdfminer.six: To handle PDF CV uploads directly in Kaggle (requires uploading the PDF to your notebook's data)."
      ],
      "metadata": {
        "id": "yIrLle0Mm75Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -qqy jupyterlab-lsp  # Remove unused conflicting packages\n",
        "!pip install -U -q \"google-genai==1.7.0\"\n",
        "#!pip install -q transformers torch accelerate bitsandbytes # For running Hugging Face models\n",
        "#!pip install -q langchain langchain_community langchain_huggingface # To use LangChain framework\n",
        "!pip install -q google-generativeai # Google AI Client Library\n",
        "!pip install -q beautifulsoup4 requests # For web scraping\n",
        "#!pip install -q sentence_transformers # Useful for semantic comparison if needed\n",
        "!pip install -q pdfminer.six # To upload/read PDF CVs\n",
        "!pip install validators\n",
        "# Placeholder for other libraries\n",
        "\n",
        "print(\"Libraries installed.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:01:07.775655Z",
          "iopub.execute_input": "2025-04-20T18:01:07.776052Z",
          "iopub.status.idle": "2025-04-20T18:01:28.790569Z",
          "shell.execute_reply.started": "2025-04-20T18:01:07.776019Z",
          "shell.execute_reply": "2025-04-20T18:01:28.789024Z"
        },
        "id": "oOrpn-LSm75Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "genai.__version__"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T17:55:57.300089Z",
          "iopub.execute_input": "2025-04-20T17:55:57.30106Z",
          "iopub.status.idle": "2025-04-20T17:55:59.053352Z",
          "shell.execute_reply.started": "2025-04-20T17:55:57.301023Z",
          "shell.execute_reply": "2025-04-20T17:55:59.052362Z"
        },
        "id": "0rlGpJ3Qm75Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from kaggle_secrets import UserSecretsClient # Assuming this is how you get secrets\n",
        "\n",
        "try:\n",
        "    user_secrets = UserSecretsClient()\n",
        "    GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
        "\n",
        "    # --- Add these lines for debugging ---\n",
        "    print(f\"Type of genai: {type(genai)}\")\n",
        "    print(f\"Attributes of genai: {dir(genai)}\")\n",
        "    # --- End of debugging lines ---\n",
        "\n",
        "    genai.configure(api_key=GOOGLE_API_KEY) # Line causing the error\n",
        "    print(\"Google AI Client Configured.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error configuring Google AI Client: {e}\") # Print the specific error\n",
        "    print(\"Please ensure your GOOGLE_API_KEY secret is set correctly.\")\n",
        "    # Handle the error appropriately, maybe raise it or exit\n",
        "    raise e"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:01:38.726492Z",
          "iopub.execute_input": "2025-04-20T18:01:38.726815Z",
          "iopub.status.idle": "2025-04-20T18:01:39.008692Z",
          "shell.execute_reply.started": "2025-04-20T18:01:38.726789Z",
          "shell.execute_reply": "2025-04-20T18:01:39.006935Z"
        },
        "id": "QwwyvOOdm75Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TeX Live\n",
        "# --- Install LaTeX ---\n",
        "print(\"Installing TeX Live, this might take a few minutes...\")\n",
        "!sudo apt-get update > /dev/null # Suppress lengthy output\n",
        "!sudo apt-get install -y texlive texlive-latex-recommended texlive-fonts-recommended latexmk > /dev/null\n",
        "!sudo apt-get install -y texlive-latex-base texlive-latex-extra texlive-fonts-extra > /dev/null\n",
        "print(\"TeX Live installation complete.\")\n",
        "\n",
        "# Verify installation (optional)\n",
        "!pdflatex -version\n",
        "!latexmk -version"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:18:16.935388Z",
          "iopub.execute_input": "2025-04-20T18:18:16.935812Z",
          "iopub.status.idle": "2025-04-20T18:21:48.178211Z",
          "shell.execute_reply.started": "2025-04-20T18:18:16.935772Z",
          "shell.execute_reply": "2025-04-20T18:21:48.176686Z"
        },
        "id": "EFNKwAqem75a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries:"
      ],
      "metadata": {
        "id": "jlDd_B-sm75a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "import pandas as pd # Optional: for better display\n",
        "\n",
        "# --- List Available Models ---\n",
        "print(\"\\nFetching available models...\")\n",
        "models_list = []\n",
        "try:\n",
        "    for m in genai.list_models():\n",
        "        # Check if the model supports the 'generateContent' method (standard text generation)\n",
        "        # This helps filter out specialized models if you only want text generators\n",
        "        if 'generateContent' in m.supported_generation_methods:\n",
        "            model_info = {\n",
        "                'name': m.name,\n",
        "                'display_name': m.display_name,\n",
        "                'description': m.description,\n",
        "                'version': m.version,\n",
        "                # Add other potentially useful fields:\n",
        "                # 'input_token_limit': m.input_token_limit,\n",
        "                # 'output_token_limit': m.output_token_limit,\n",
        "            }\n",
        "            models_list.append(model_info)\n",
        "\n",
        "    if not models_list:\n",
        "        print(\"No models supporting 'generateContent' found or API call failed.\")\n",
        "    else:\n",
        "        print(f\"Found {len(models_list)} models supporting 'generateContent':\")\n",
        "\n",
        "        # --- Filter for \"Pro\" models (Case-Insensitive Search) ---\n",
        "        pro_models = [\n",
        "            model for model in models_list\n",
        "            if 'pro' in model['name'].lower() or 'pro' in model['display_name'].lower()\n",
        "        ]\n",
        "\n",
        "        print(\"\\n--- All Found Text Generation Models ---\")\n",
        "        # Optional: Display as a Pandas DataFrame for nicer formatting\n",
        "        all_models_df = pd.DataFrame(models_list)\n",
        "        #display(all_models_df[['name', 'display_name', 'version', 'description']]) # Use display() in Kaggle\n",
        "\n",
        "        print(\"\\n--- Filtered 'Pro' Models ---\")\n",
        "        if pro_models:\n",
        "            pro_models_df = pd.DataFrame(pro_models)\n",
        "            display(pro_models_df[['name', 'display_name', 'version', 'description']])\n",
        "        else:\n",
        "            print(\"No models containing 'Pro' found in the results.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing models: {e}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:01:47.82314Z",
          "iopub.execute_input": "2025-04-20T18:01:47.823523Z",
          "iopub.status.idle": "2025-04-20T18:01:49.672267Z",
          "shell.execute_reply.started": "2025-04-20T18:01:47.823492Z",
          "shell.execute_reply": "2025-04-20T18:01:49.671343Z"
        },
        "id": "KiPRUwyvm75b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "import json # For handling JSON output\n",
        "import time # For potential retries\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        "import re # Useful for cleaning/parsing text\n",
        "\n",
        "# --- Model Configuration ---\n",
        "# MODEL_NAME = \"gemini-1.5-flash\" # Flash is fast and capable for many tasks but I found pro better in generating text\n",
        "MODEL_NAME = \"models/gemini-2.5-pro-exp-03-25\"\n",
        "model = genai.GenerativeModel(MODEL_NAME)\n",
        "\n",
        "# --- Safety Settings (Optional but Recommended) ---\n",
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "}\n",
        "\n",
        "# --- Generation Configuration (Optional) ---\n",
        "generation_config = genai.GenerationConfig(\n",
        "    temperature=0.9, # Controls randomness (0=deterministic, >1=more creative)\n",
        "    # max_output_tokens=1024, # Limit response length\n",
        "    # response_mime_type=\"application/json\" # Use this specifically for JSON mode capability\n",
        ")\n",
        "\n",
        "print(f\"Using model: {MODEL_NAME}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:01:54.753541Z",
          "iopub.execute_input": "2025-04-20T18:01:54.754269Z",
          "iopub.status.idle": "2025-04-20T18:01:55.174632Z",
          "shell.execute_reply.started": "2025-04-20T18:01:54.754232Z",
          "shell.execute_reply": "2025-04-20T18:01:55.173694Z"
        },
        "id": "oWT0yeGHm75b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Input Data:"
      ],
      "metadata": {
        "id": "RGUOEC4gm75b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cell for Instructed Upload via Kaggle UI ---\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import os\n",
        "import time\n",
        "import validators # For URL validation later if needed\n",
        "\n",
        "# --- Global variables to store results ---\n",
        "job_posting_url = None # Assuming you still get this earlier or here\n",
        "cv_path = None\n",
        "setup_successful = False\n",
        "\n",
        "# --- Widgets ---\n",
        "# Assuming job_link is obtained previously or via input here\n",
        "# Let's add URL input back for completeness of this example cell\n",
        "url_input = widgets.Text(\n",
        "    placeholder='Paste job description URL here...',\n",
        "    description='Job URL:',\n",
        "    layout=widgets.Layout(width='80%'),\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Instructions for CV upload using Kaggle UI\n",
        "upload_instructions = widgets.HTML(\n",
        "    value=\"\"\"\n",
        "    <hr>\n",
        "    <b>Step 2: Upload Your CV using Kaggle UI</b>\n",
        "    <ol>\n",
        "        <li>Go to the <b>\"File\" menu</b> at the top-left OR use the <b>\"+ Add data\" button</b> in the right sidebar.</li>\n",
        "        <li>Select <b>\"Upload Data\"</b>.</li>\n",
        "        <li>Click <b>\"Browse Files\"</b> and select your CV file (e.g., MyResume.pdf).</li>\n",
        "        <li>Give your upload a simple dataset title if prompted (e.g., \"cv-upload\").</li>\n",
        "        <li>Wait for the upload to complete.</li>\n",
        "        <li>Find your uploaded file in the Input section of the right sidebar (it might take a moment to appear).</li>\n",
        "        <li><b>Copy the exact file path</b> (e.g., <code>/kaggle/input/cv-upload/MyResume.pdf</code>).</li>\n",
        "        <li><b>Paste the full path</b> into the text box below and click \"Confirm Path\".</li>\n",
        "    </ol>\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Text input for the user to paste the path\n",
        "path_input = widgets.Text(\n",
        "    placeholder='/kaggle/input/your-dataset-name/your-cv.pdf',\n",
        "    description='CV Path:',\n",
        "    layout=widgets.Layout(width='80%'),\n",
        "    disabled=True # Disabled until URL is entered\n",
        ")\n",
        "\n",
        "# Button to confirm the pasted path\n",
        "confirm_button = widgets.Button(\n",
        "    description=\"Confirm URL & CV Path\",\n",
        "    button_style='success',\n",
        "    tooltip='Click after entering URL and pasting the CV path from /kaggle/input/',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Output area for messages\n",
        "output_area = widgets.Output()\n",
        "\n",
        "# --- Event Handlers ---\n",
        "\n",
        "def handle_confirmation(button_instance):\n",
        "    global job_posting_url, cv_path, setup_successful, path_input, url_input # Allow modification\n",
        "\n",
        "    # Disable inputs during processing\n",
        "    url_input.disabled = True\n",
        "    path_input.disabled = True\n",
        "    confirm_button.disabled = True\n",
        "\n",
        "    with output_area:\n",
        "        clear_output(wait=True)\n",
        "        print(\"Processing...\")\n",
        "        time.sleep(0.5)\n",
        "\n",
        "        # 1. Validate URL\n",
        "        temp_job_link = url_input.value.strip()\n",
        "        if not validators.url(temp_job_link):\n",
        "             print(f\"❌ Error: Invalid Job URL provided: '{temp_job_link}'\")\n",
        "             # Re-enable inputs and return\n",
        "             url_input.disabled = False\n",
        "             path_input.disabled = True # Keep path disabled until URL is valid\n",
        "             confirm_button.disabled = False\n",
        "             return\n",
        "        else:\n",
        "            job_posting_url = temp_job_link # Store valid URL\n",
        "            print(f\"✅ Job URL confirmed: {job_posting_url}\")\n",
        "            path_input.disabled = False # Enable path input now URL is okay\n",
        "\n",
        "        # 2. Validate Pasted CV Path\n",
        "        temp_cv_path = path_input.value.strip()\n",
        "        # Remove surrounding quotes if user pastes path with them\n",
        "        if temp_cv_path.startswith('\"') and temp_cv_path.endswith('\"'):\n",
        "            temp_cv_path = temp_cv_path[1:-1]\n",
        "        elif temp_cv_path.startswith(\"'\") and temp_cv_path.endswith(\"'\"):\n",
        "            temp_cv_path = temp_cv_path[1:-1]\n",
        "\n",
        "\n",
        "        if not temp_cv_path:\n",
        "            print(\"❌ Error: Please paste the CV file path from /kaggle/input/.\")\n",
        "        elif not temp_cv_path.startswith(\"/kaggle/input/\"):\n",
        "             print(f\"❌ Error: Path should start with '/kaggle/input/'. You entered: '{temp_cv_path}'\")\n",
        "        elif not os.path.exists(temp_cv_path):\n",
        "             print(f\"❌ Error: File not found at path '{temp_cv_path}'. Double-check the path in the sidebar.\")\n",
        "        elif not os.path.isfile(temp_cv_path):\n",
        "             print(f\"❌ Error: Path '{temp_cv_path}' points to a directory, not a file.\")\n",
        "        else:\n",
        "            # --- Success ---\n",
        "            cv_path = temp_cv_path # Store the validated path\n",
        "            setup_successful = True\n",
        "            print(f\"✅ CV Path confirmed: {cv_path}\")\n",
        "            print(\"\\n--- Setup Complete ---\")\n",
        "            print(\"You can now proceed with the next steps in your notebook.\")\n",
        "            # Inputs remain disabled on success\n",
        "            return # Exit function successfully\n",
        "\n",
        "        # --- If any validation failed ---\n",
        "        setup_successful = False\n",
        "        cv_path = None\n",
        "        # Re-enable inputs for correction (URL stays enabled, path too now)\n",
        "        url_input.disabled = False\n",
        "        path_input.disabled = False\n",
        "        confirm_button.disabled = False\n",
        "\n",
        "\n",
        "# --- Link Event Handler ---\n",
        "confirm_button.on_click(handle_confirmation)\n",
        "\n",
        "# --- Display Widgets ---\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<b>Step 1: Enter Job Description URL</b>\"),\n",
        "    url_input,\n",
        "    upload_instructions, # Display the HTML instructions\n",
        "    path_input,\n",
        "    confirm_button,\n",
        "    output_area\n",
        "]))\n",
        "#job_posting_url = \"https://www.amazon.jobs/en/jobs/2956591/embedded-software-development-engineer-blink?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:02:06.11778Z",
          "iopub.execute_input": "2025-04-20T18:02:06.118651Z",
          "iopub.status.idle": "2025-04-20T18:02:06.176785Z",
          "shell.execute_reply.started": "2025-04-20T18:02:06.118614Z",
          "shell.execute_reply": "2025-04-20T18:02:06.175567Z"
        },
        "id": "xabMXfG1m75c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- INPUT SECTION ---\n",
        "# Define the job URL (manual input)\n",
        "job_posting_url = \"https://www.amazon.jobs/en/jobs/2956591/embedded-software-development-engineer-blink?cmpid=SPLICX0248M&utm_source=linkedin.com&utm_campaign=cxro&utm_medium=social_media&utm_content=job_posting&ss=paid\"\n",
        "\n",
        "# --- PDF INPUT SECTION ---\n",
        "\n",
        "# IMPORTANT: Update this path based on your dataset name and PDF filename!\n",
        "# Example: If dataset is 'cv-data' and file is 'MyResume_Jan2024.pdf'\n",
        "# pdf_path = \"/kaggle/working/MyResume_Jan2024.pdf\"\n",
        "\n",
        "# --- Try to auto-detect the first PDF found ---\n",
        "pdf_path = None\n",
        "input_dirs = [d for d in os.listdir('/kaggle/input') if os.path.isdir(os.path.join('/kaggle/input', d))]\n",
        "\n",
        "if not input_dirs:\n",
        "    print(\"Warning: No input directories found in /kaggle/input/. Did you add data?\")\n",
        "else:\n",
        "    # Search for the first file ending in .pdf\n",
        "    for dirname in input_dirs:\n",
        "        dirpath = os.path.join('/kaggle/input', dirname)\n",
        "        try:\n",
        "            for filename in os.listdir(dirpath):\n",
        "                if filename.lower().endswith('.pdf'):\n",
        "                    pdf_path = os.path.join(dirpath, filename)\n",
        "                    print(f\"Found PDF: {pdf_path}\")\n",
        "                    break # Use the first PDF found\n",
        "        except Exception as e:\n",
        "            print(f\"Could not list files in {dirpath}: {e}\")\n",
        "        if pdf_path:\n",
        "             break # Stop searching once one is found\n",
        "\n",
        "# --- Define path manually if auto-detect fails or is wrong ---\n",
        "# pdf_path = \"/kaggle/working/YOUR_CV_FILENAME.pdf\" # UNCOMMENT AND SET MANUALLY IF NEEDED\n",
        "\n",
        "base_cv_text = None\n",
        "if pdf_path and os.path.exists(pdf_path):\n",
        "    print(f\"Attempting to read text from: {pdf_path}\")\n",
        "    try:\n",
        "        base_cv_text = extract_text(pdf_path)\n",
        "        print(f\"Successfully extracted text from PDF. Length: {len(base_cv_text)} characters.\")\n",
        "        # Optional: Print a snippet to verify\n",
        "        # print(\"\\n--- Start of Extracted CV Text ---\")\n",
        "        # print(base_cv_text[:500])\n",
        "        # print(\"--- End of Snippet ---\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from PDF '{pdf_path}': {e}\")\n",
        "        print(\"Please ensure it's a text-based PDF and not an image scan.\")\n",
        "        # Optional: Provide fallback mechanism\n",
        "        # base_cv_text = \"\"\" PASTE YOUR CV TEXT HERE AS A FALLBACK \"\"\"\n",
        "else:\n",
        "    if not pdf_path:\n",
        "         print(\"Error: Could not automatically find a PDF file in /kaggle/input/.\")\n",
        "    else:\n",
        "         print(f\"Error: PDF file not found at specified path: {pdf_path}\")\n",
        "    print(\"Please ensure you have added your CV PDF via '+ Add Data' and the path is correct.\")\n",
        "    # Stop execution or use fallback\n",
        "    # raise FileNotFoundError(\"CV PDF not found or readable.\")\n",
        "\n",
        "# --- Ensure base_cv_text is not None before proceeding ---\n",
        "if base_cv_text is None:\n",
        "     raise ValueError(\"Failed to load CV text from PDF. Notebook cannot proceed.\")\n",
        "\n",
        "# Optional: Define which parts of the CV you want to target for updates\n",
        "target_sections = [\"Summary\", \"Skills\"]\n",
        "print(\"Input CV and Job URL defined.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:04:55.354989Z",
          "iopub.execute_input": "2025-04-20T18:04:55.355279Z",
          "iopub.status.idle": "2025-04-20T18:04:55.503592Z",
          "shell.execute_reply.started": "2025-04-20T18:04:55.355257Z",
          "shell.execute_reply": "2025-04-20T18:04:55.502222Z"
        },
        "id": "foOYRS4mm75c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adjust Section Parsing:"
      ],
      "metadata": {
        "id": "ZZx1r2Cem75c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've tried using re to extract and scrape data, but since I want to make it more general I decided to ask LLM to go through\n",
        "input CV and detect sections"
      ],
      "metadata": {
        "id": "GNN8hIJPm75c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define helper function for text generation:"
      ],
      "metadata": {
        "id": "1dzOczzwm75c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_with_gemini(prompt_text, is_json_output=False):\n",
        "    \"\"\"Generates text using the Gemini model with error handling.\"\"\"\n",
        "    try:\n",
        "        current_config = generation_config\n",
        "        if is_json_output:\n",
        "            # Ensure the specific model supports JSON output mode if explicitly requesting\n",
        "            # Check Gemini docs. If not directly supported via MIME type,\n",
        "            # instruct the model clearly in the prompt to ONLY output valid JSON.\n",
        "            current_config = genai.GenerationConfig(\n",
        "                 response_mime_type=\"application/json\"\n",
        "                 # Add other config like temperature if needed\n",
        "            )\n",
        "            print(\"Attempting JSON output mode.\")\n",
        "\n",
        "\n",
        "        response = model.generate_content(\n",
        "            prompt_text,\n",
        "            generation_config=current_config,\n",
        "            safety_settings=safety_settings\n",
        "        )\n",
        "\n",
        "        # Handle potential safety blocks or empty responses\n",
        "        if not response.candidates:\n",
        "             print(\"Warning: Response blocked or empty. Safety ratings:\", response.prompt_feedback.safety_ratings)\n",
        "             return None\n",
        "\n",
        "        # Accessing the text - check Gemini API documentation for the exact structure\n",
        "        # It might be response.text or response.candidates[0].content.parts[0].text\n",
        "        generated_content = response.text\n",
        "\n",
        "        if is_json_output:\n",
        "             # Validate if the output is actually JSON\n",
        "             try:\n",
        "                 json.loads(generated_content)\n",
        "                 print(\"Valid JSON received.\")\n",
        "             except json.JSONDecodeError:\n",
        "                 print(\"Warning: Model did not return valid JSON despite request.\")\n",
        "                 print(\"Raw output:\", generated_content[:200]) # Print snippet for debugging\n",
        "                 # Fallback: Return raw text or None\n",
        "                 return generated_content # Or handle error differently\n",
        "\n",
        "        return generated_content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Gemini API call: {e}\")\n",
        "        # Implement retry logic if desired (e.g., for rate limits)\n",
        "        # time.sleep(5) # Simple backoff\n",
        "        return None # Or re-raise the exception"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:05:03.744253Z",
          "iopub.execute_input": "2025-04-20T18:05:03.744654Z",
          "iopub.status.idle": "2025-04-20T18:05:03.752489Z",
          "shell.execute_reply.started": "2025-04-20T18:05:03.744628Z",
          "shell.execute_reply": "2025-04-20T18:05:03.751433Z"
        },
        "id": "9wvmW6kAm75d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- LLM-Based Section Extraction ---\n",
        "\n",
        "print(\"Attempting to extract Summary and Skills sections using LLM...\")\n",
        "base_summary = \"Summary could not be extracted by LLM.\" # Default fallback\n",
        "base_skills_section = \"Skills section could not be extracted by LLM.\" # Default fallback\n",
        "\n",
        "if base_cv_text: # Only proceed if PDF text was loaded\n",
        "    # --- Prepare the Prompt for Section Extraction ---\n",
        "    prompt_extract_sections = f\"\"\"\n",
        "    Analyze the following CV text and identify the main \"Summary\" (or Objective/Profile) section and the primary \"Skills\" (or Key Skills/Technical Skills/Competencies) section.\n",
        "\n",
        "    CV Text:\n",
        "    ---\n",
        "    {base_cv_text}\n",
        "    ---\n",
        "\n",
        "    Task: Extract the full text content for these two sections.\n",
        "    IMPORTANT: Respond ONLY with a valid JSON object containing two keys:\n",
        "    1.  \"summary\": A string containing the full text of the candidate's summary/objective/profile section. If no such section is clearly identifiable, return null or an empty string.\n",
        "    2.  \"skills\": A string containing the full text of the main skills listing section. This often includes bullet points. If no such section is clearly identifiable, return null or an empty string.\n",
        "\n",
        "    Do not include any introductory text, explanations, or markdown formatting outside the JSON object itself.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Requesting section extraction from LLM...\")\n",
        "    # Use the helper function, requesting JSON output\n",
        "    extracted_sections_json_str = generate_text_with_gemini(prompt_extract_sections, is_json_output=True)\n",
        "\n",
        "    if extracted_sections_json_str:\n",
        "        try:\n",
        "            # Clean potential markdown code block fences ```json ... ``` or ``` ... ```\n",
        "            if extracted_sections_json_str.strip().startswith(\"```json\"):\n",
        "                 extracted_sections_json_str = extracted_sections_json_str.strip()[7:-3].strip()\n",
        "            elif extracted_sections_json_str.strip().startswith(\"```\"):\n",
        "                 extracted_sections_json_str = extracted_sections_json_str.strip()[3:-3].strip()\n",
        "\n",
        "            # Parse the JSON response\n",
        "            extracted_sections = json.loads(extracted_sections_json_str)\n",
        "            print(\"--- Extracted Job Information (JSON Parsed & Pretty Printed) ---\")\n",
        "            # Use json.dumps() with indent for pretty printing\n",
        "            print(json.dumps(extracted_sections, indent=2)) # <--- CHANGE/VERIFY THIS LINE\n",
        "\n",
        "            # Assign the extracted content, providing fallbacks if keys are missing or null\n",
        "            base_summary = extracted_sections.get(\"summary\") or base_summary # Use fallback if null/empty\n",
        "            base_skills_section = extracted_sections.get(\"skills\") or base_skills_section # Use fallback if null/empty\n",
        "\n",
        "            if not extracted_sections.get(\"summary\"):\n",
        "                 print(\"Warning: LLM did not identify a 'summary' section.\")\n",
        "            if not extracted_sections.get(\"skills\"):\n",
        "                 print(\"Warning: LLM did not identify a 'skills' section.\")\n",
        "\n",
        "            print(f\"LLM-Extracted Professional Summary (Snippet): {base_summary[:150]}...\")\n",
        "            print(f\"LLM-Extracted Key Skills Section (Snippet): {base_skills_section[:150]}...\")\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error parsing JSON response from LLM for section extraction: {e}\")\n",
        "            print(\"Raw Response Snippet:\", extracted_sections_json_str[:500])\n",
        "            # Keep the default fallback values\n",
        "        except Exception as e:\n",
        "             print(f\"An unexpected error occurred processing the LLM response for section extraction: {e}\")\n",
        "             print(\"Raw Response Snippet:\", extracted_sections_json_str[:500])\n",
        "             # Keep the default fallback values\n",
        "    else:\n",
        "        print(\"LLM did not return a response for section extraction.\")\n",
        "        # Keep the default fallback values\n",
        "\n",
        "else:\n",
        "    print(\"Skipping LLM section extraction as base_cv_text is not loaded.\")\n",
        "\n",
        "# --- Ensure the variables are ready for use in subsequent prompts ---\n",
        "# The variables base_summary and base_skills_section now hold the text extracted by the LLM\n",
        "# or the default error message if extraction failed or sections weren't found.\n",
        "\n",
        "if base_summary.startswith(\"Summary could not\"):\n",
        "    print(\"Warning: Proceeding without a clearly identified summary section.\")\n",
        "if base_skills_section.startswith(\"Skills section could not\"):\n",
        "     print(\"Warning: Proceeding without a clearly identified skills section.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:05:08.622331Z",
          "iopub.execute_input": "2025-04-20T18:05:08.622717Z",
          "iopub.status.idle": "2025-04-20T18:05:14.573979Z",
          "shell.execute_reply.started": "2025-04-20T18:05:08.62269Z",
          "shell.execute_reply": "2025-04-20T18:05:14.572542Z"
        },
        "id": "SdjtlISjm75d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction and Procesing:"
      ],
      "metadata": {
        "id": "6qjTt-6lm75d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function uses requests to get page HTML and uses BeautifulSoup to parse it. The text content is then given to LLM with prompt with some exmaples and output format."
      ],
      "metadata": {
        "id": "1ZTrxEaem75d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_job_description(url):\n",
        "    \"\"\"\n",
        "    Fetches content from a URL, extracts all text, and then uses\n",
        "    an LLM to identify and return only the core job description.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- Step 1: Fetch and Parse Initial HTML ---\n",
        "        response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=20) # Added timeout\n",
        "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # --- Step 2: Extract All Text (Initial Noisy Extraction) ---\n",
        "        # Getting all text is often necessary as specific containers fail\n",
        "        all_text = ' '.join(soup.stripped_strings)\n",
        "\n",
        "        if not all_text:\n",
        "            print(f\"Warning: No text could be extracted from {url} using BeautifulSoup.\")\n",
        "            return None # Return None if no text found at all\n",
        "\n",
        "        print(f\"Initial text extracted (length {len(all_text)}). Asking LLM to find job description...\")\n",
        "        # print(f\"Initial text snippet: {all_text[:500]}...\") # Optional: for debugging\n",
        "\n",
        "        # --- Step 3: Use LLM to Extract Core Job Description ---\n",
        "        # Limit input length to avoid exceeding token limits (adjust as needed)\n",
        "        # Gemini models often have large context windows, but let's be safe.\n",
        "        max_input_chars = 25000 # Example limit, adjust based on model and typical page size\n",
        "        input_text_for_llm = all_text[:max_input_chars]\n",
        "\n",
        "        prompt_llm_extract_jd = f\"\"\"\n",
        "        Analyze the following text extracted from a webpage ({url}). This text contains the entire page content, including headers, footers, navigation, ads, and potentially the job description.\n",
        "\n",
        "        Your task is to identify and extract ONLY the core job description content. This typically includes sections like:\n",
        "        - Job Title / Role Name\n",
        "        - Company Information (briefly, if relevant to the role itself)\n",
        "        - Responsibilities / What You'll Do\n",
        "        - Requirements / Qualifications / Who You Are\n",
        "        - Nice-to-haves / Preferred Qualifications\n",
        "        - Location / Remote work details (if part of the description)\n",
        "        - Sometimes details about the team or company culture within the description body.\n",
        "\n",
        "        Explicitly EXCLUDE common irrelevant page elements such as:\n",
        "        - Main site navigation menus (e.g., links to Home, About Us, Careers Home)\n",
        "        - Footer text (copyrights, privacy policy links)\n",
        "        - Cookie consent banners\n",
        "        - Advertisements or links to unrelated jobs\n",
        "        - Application form fields or instructions (\"Apply Now\" buttons, \"Upload Resume\") unless they are literally the only text available.\n",
        "        - Boilerplate text repeated on many pages (e.g., general diversity statements unless part of the JD itself).\n",
        "\n",
        "        If a clear job description section cannot be found, return the phrase \"No specific job description found.\"\n",
        "\n",
        "        Extracted Webpage Text:\n",
        "        ---\n",
        "        {input_text_for_llm}\n",
        "        ---\n",
        "\n",
        "        Extracted Job Description:\n",
        "        \"\"\"\n",
        "\n",
        "        # Use the existing helper function (assuming it's defined)\n",
        "        cleaned_job_description = generate_text_with_gemini(prompt_llm_extract_jd, is_json_output=False) # Not requesting JSON here\n",
        "\n",
        "        if cleaned_job_description and \"No specific job description found.\" not in cleaned_job_description:\n",
        "            print(\"LLM successfully extracted potential job description.\")\n",
        "            return cleaned_job_description.strip()\n",
        "        elif cleaned_job_description:\n",
        "             print(\"LLM indicated no specific job description was found in the text.\")\n",
        "             return None # Return None if LLM explicitly says it can't find it\n",
        "        else:\n",
        "            print(\"Warning: LLM extraction failed or returned empty. Falling back to raw text (potentially noisy).\")\n",
        "            # Fallback: Return the noisy text if LLM fails, but maybe truncated? Or return None?\n",
        "            # Returning None might be safer if the LLM step is crucial.\n",
        "            # return all_text[:5000] # Example: Return truncated raw text as last resort\n",
        "            return None # Let's return None if LLM step fails, as raw text was problematic\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "         print(f\"Error: Request timed out for URL {url}\")\n",
        "         return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching URL {url}: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        # Catch potential errors in BeautifulSoup or the LLM call within this function\n",
        "        print(f\"Error processing content from {url}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:05:23.356672Z",
          "iopub.execute_input": "2025-04-20T18:05:23.357578Z",
          "iopub.status.idle": "2025-04-20T18:05:23.366324Z",
          "shell.execute_reply.started": "2025-04-20T18:05:23.357548Z",
          "shell.execute_reply": "2025-04-20T18:05:23.365309Z"
        },
        "id": "7TGXq3fRm75d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch and print the job description\n",
        "job_description = scrape_job_description(job_posting_url)\n",
        "\n",
        "if job_description:\n",
        "    print(\"--- Scraped Job Description (First 500 chars) ---\")\n",
        "    print(job_description[:500])\n",
        "    print(\"\\n--- End of Snippet ---\")\n",
        "else:\n",
        "    print(\"Failed to retrieve job description.\")\n",
        "    # You might want to stop execution or handle this error\n",
        "    if not job_description: # Still no JD? Stop.\n",
        "        raise ValueError(\"Job Description could not be obtained.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:05:31.429828Z",
          "iopub.execute_input": "2025-04-20T18:05:31.430143Z",
          "iopub.status.idle": "2025-04-20T18:05:49.759643Z",
          "shell.execute_reply.started": "2025-04-20T18:05:31.430122Z",
          "shell.execute_reply": "2025-04-20T18:05:49.758406Z"
        },
        "id": "oB2LMlnam75d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply Gen AI Techniques:"
      ],
      "metadata": {
        "id": "fQEc939Km75e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use LLM to extract info from Job Description in JSON format:"
      ],
      "metadata": {
        "id": "5Z1w9vv-m75e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_extract_json = f\"\"\"\n",
        "Analyze the following job description and extract key information.\n",
        "IMPORTANT: Respond ONLY with a valid JSON object containing the following keys:\n",
        "- \"required_skills\": A list of strings detailing specific technical and soft skills mentioned.\n",
        "- \"key_responsibilities\": A list of strings summarizing the main duties and tasks.\n",
        "- \"company_focus_values\": A brief string describing any stated company culture, values, or product focus. If none are explicitly mentioned, state \"Not specified\".\n",
        "- \"job_title\": The job title mentioned in the description. If not clear, state \"Not specified\".\n",
        "- \"experience_level\": Required or desired experience level (e.g., \"Entry-level\", \"5+ years\", \"Senior\"). If not clear, state \"Not specified\".\n",
        "\n",
        "Do not include any introductory text or explanations outside the JSON object.\n",
        "\n",
        "Job Description Text (first ~3000 chars):\n",
        "---\n",
        "{job_description[:3000]}\n",
        "---\n",
        "\n",
        "JSON Output:\n",
        "\"\"\"\n",
        "\n",
        "print(\"Requesting structured information from Job Description...\")\n",
        "extracted_info_json_str = generate_text_with_gemini(prompt_extract_json, is_json_output=True) # Request JSON\n",
        "\n",
        "extracted_info = None\n",
        "if extracted_info_json_str:\n",
        "    try:\n",
        "        # Clean potential markdown code block fences ```json ... ```\n",
        "        if extracted_info_json_str.strip().startswith(\"```json\"):\n",
        "             extracted_info_json_str = extracted_info_json_str.strip()[7:-3].strip()\n",
        "        elif extracted_info_json_str.strip().startswith(\"```\"):\n",
        "             extracted_info_json_str = extracted_info_json_str.strip()[3:-3].strip()\n",
        "\n",
        "        extracted_info = json.loads(extracted_info_json_str)\n",
        "        print(\"--- Extracted Job Information (JSON Parsed) ---\")\n",
        "        # Pretty print the JSON\n",
        "        print(json.dumps(extracted_info, indent=2))\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error parsing JSON response: {e}\")\n",
        "        print(\"Raw Response Snippet:\", extracted_info_json_str[:500])\n",
        "        # Handle the error - maybe try a non-JSON prompt as fallback?\n",
        "    except Exception as e:\n",
        "         print(f\"An unexpected error occurred processing the response: {e}\")\n",
        "         print(\"Raw Response Snippet:\", extracted_info_json_str[:500])\n",
        "\n",
        "if not extracted_info:\n",
        "    print(\"Could not extract structured information. Proceeding with caution.\")\n",
        "    # You might need to handle this case downstream (e.g., skip steps relying on this info)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:05:55.648702Z",
          "iopub.execute_input": "2025-04-20T18:05:55.649055Z",
          "iopub.status.idle": "2025-04-20T18:06:03.917977Z",
          "shell.execute_reply.started": "2025-04-20T18:05:55.649031Z",
          "shell.execute_reply": "2025-04-20T18:06:03.916959Z"
        },
        "id": "1ipPqujqm75e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Few-Shot Promptng to Generate Tailored CV Summary:"
      ],
      "metadata": {
        "id": "25dpiIJfm75e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure we have extracted info, even if basic\n",
        "job_skills_str = \", \".join(extracted_info.get('required_skills', [])) if extracted_info else \"relevant skills\"\n",
        "job_resp_str = \"; \".join(extracted_info.get('key_responsibilities', [])) if extracted_info else \"key duties\"\n",
        "\n",
        "\n",
        "# --- Construct the Few-Shot Prompt ---\n",
        "prompt_rewrite_summary_few_shot = f\"\"\"\n",
        "You are an expert resume writer. Your task is to rewrite a generic CV summary to be specifically tailored for a job description.\n",
        "\n",
        "**Example 1:**\n",
        "Generic Summary: Results-oriented Marketing Manager with 8 years of experience in digital campaigns and team leadership. Proven ability to increase brand awareness.\n",
        "Job Highlights: Seeking B2B SaaS Marketing Lead. Requires expertise in SEO, content marketing for lead generation, and managing marketing automation platforms (HubSpot).\n",
        "Tailored Summary: Experienced B2B SaaS Marketing Manager with 8 years driving lead generation through strategic SEO and content marketing. Proficient in HubSpot, focused on increasing qualified leads for SaaS products.\n",
        "\n",
        "**Example 2:**\n",
        "Generic Summary: Detail-oriented Data Analyst skilled in SQL, Python, and data visualization. Experience cleaning and interpreting large datasets.\n",
        "Job Highlights: Junior Data Analyst role focused on retail analytics. Needs experience with Tableau for dashboarding and presenting findings to non-technical stakeholders.\n",
        "Tailored Summary: Data Analyst proficient in SQL and Python, with experience in retail analytics. Skilled in transforming complex data into actionable insights using Tableau dashboards and communicating findings clearly to business stakeholders.\n",
        "\n",
        "**Now, perform the task for the following:**\n",
        "\n",
        "Generic Summary:\n",
        "{base_summary}\n",
        "\n",
        "Job Highlights:\n",
        "- Key Skills: {job_skills_str}\n",
        "- Responsibilities: {job_resp_str}\n",
        "- Job Title: {extracted_info.get('job_title', 'Not specified') if extracted_info else 'Not specified'}\n",
        "\n",
        "Rewrite the generic summary (2-4 sentences) to strongly align with the specific Job Highlights provided above. Focus on the most relevant skills and experiences mentioned in the generic summary that match the job requirements.\n",
        "\n",
        "Tailored CV Summary:\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nRequesting tailored CV summary using Few-Shot Prompting...\")\n",
        "tailored_summary = generate_text_with_gemini(prompt_rewrite_summary_few_shot)\n",
        "\n",
        "print(\"\\n--- Original CV Summary ---\")\n",
        "print(base_summary)\n",
        "print(\"\\n--- Generated Tailored CV Summary ---\")\n",
        "if tailored_summary:\n",
        "    print(tailored_summary)\n",
        "else:\n",
        "    print(\"Failed to generate tailored summary.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:06:08.748071Z",
          "iopub.execute_input": "2025-04-20T18:06:08.748439Z",
          "iopub.status.idle": "2025-04-20T18:06:25.468143Z",
          "shell.execute_reply.started": "2025-04-20T18:06:08.74841Z",
          "shell.execute_reply": "2025-04-20T18:06:25.467108Z"
        },
        "id": "zXyvxumam75e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Document Understanding to Compare skills and suggest additions or rephrasing:"
      ],
      "metadata": {
        "id": "LGtSBR5dm75e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_skills_section = \"[Skills]...\" # Extract the skills section from base_cv_text\n",
        "# Simple extraction\n",
        "try:\n",
        "     skills_start = base_cv_text.find(\"**Skills**\") + len(\"**Skills**\")\n",
        "     skills_end = base_cv_text.find(\"**Education**\") # Assumes Education follows Skills\n",
        "     if skills_start > -1 and skills_end > -1:\n",
        "          base_skills_section = base_cv_text[skills_start:skills_end].strip()\n",
        "     elif skills_start > -1: # If Skills is the last section\n",
        "          base_skills_section = base_cv_text[skills_start:].strip()\n",
        "     else:\n",
        "          base_skills_section = \"No skills section found.\"\n",
        "except Exception:\n",
        "     base_skills_section = \"Error extracting skills.\"\n",
        "\n",
        "\n",
        "# Ensure we have the required skills list from the structured extraction\n",
        "required_skills_list = extracted_info.get('required_skills', []) if extracted_info else []\n",
        "\n",
        "if not required_skills_list:\n",
        "    print(\"\\nWarning: Cannot perform skill matching as required skills were not extracted.\")\n",
        "    skill_analysis = \"Skipped - Required skills not available.\"\n",
        "else:\n",
        "    prompt_skill_match = f\"\"\"\n",
        "    Analyze the alignment between the candidate's current CV skills and the required skills for the job.\n",
        "\n",
        "    Candidate's Current CV Skills Section:\n",
        "    ---\n",
        "    {base_skills_section}\n",
        "    ---\n",
        "\n",
        "    Required Skills from Job Description:\n",
        "    ---\n",
        "    {', '.join(required_skills_list)}\n",
        "    ---\n",
        "\n",
        "    Task:\n",
        "    1.  Identify which **Required Skills** seem to be **present** in the Candidate's CV Skills Section (list them). Interpret skills broadly (e.g., 'AWS EC2' in CV matches 'AWS' or 'Cloud Computing' requirement).\n",
        "    2.  Identify key **Required Skills** that appear to be **missing** or not explicitly mentioned in the Candidate's CV Skills Section (list them).\n",
        "    3.  Suggest 1-2 high-priority skills from the **missing** list that the candidate should consider adding or elaborating on in their CV, potentially by rephrasing existing experience if applicable.\n",
        "\n",
        "    Provide the analysis clearly under the headings: \"Present Skills:\", \"Missing Skills:\", and \"Suggestions:\".\n",
        "\n",
        "    Analysis:\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nRequesting Skill Analysis (Document Understanding)...\")\n",
        "    skill_analysis = generate_text_with_gemini(prompt_skill_match)\n",
        "\n",
        "print(\"\\n--- Skills Analysis and Suggestions ---\")\n",
        "if skill_analysis:\n",
        "    print(skill_analysis)\n",
        "else:\n",
        "    print(\"Failed to generate skill analysis.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:06:32.241397Z",
          "iopub.execute_input": "2025-04-20T18:06:32.241693Z",
          "iopub.status.idle": "2025-04-20T18:07:02.986345Z",
          "shell.execute_reply.started": "2025-04-20T18:06:32.24167Z",
          "shell.execute_reply": "2025-04-20T18:07:02.985547Z"
        },
        "id": "94tzpL8Um75e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Output:"
      ],
      "metadata": {
        "id": "AaaEmygfm75f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding helper function to escape Latex Charachters:"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-15T21:00:11.808012Z",
          "iopub.execute_input": "2025-04-15T21:00:11.808742Z",
          "iopub.status.idle": "2025-04-15T21:00:11.814302Z",
          "shell.execute_reply.started": "2025-04-15T21:00:11.808709Z",
          "shell.execute_reply": "2025-04-15T21:00:11.813532Z"
        },
        "id": "ZPwUiBHfm75f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def escape_latex(text):\n",
        "    \"\"\"Escapes characters special to LaTeX.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text) # Ensure input is a string\n",
        "\n",
        "    # Basic escape characters\n",
        "    conv = {\n",
        "        '&': r'\\&',\n",
        "        '%': r'\\%',\n",
        "        '$': r'\\$',\n",
        "        '#': r'\\#',\n",
        "        '_': r'\\_',\n",
        "        '{': r'\\{',\n",
        "        '}': r'\\}',\n",
        "        '~': r'\\textasciitilde{}',\n",
        "        '^': r'\\^{}',\n",
        "        '\\\\': r'\\textbackslash{}',\n",
        "        '<': r'\\textless{}',\n",
        "        '>': r'\\textgreater{}',\n",
        "    }\n",
        "    regex = re.compile('|'.join(re.escape(str(key)) for key in sorted(conv.keys(), key = lambda item: - len(item))))\n",
        "    text = regex.sub(lambda match: conv[match.group()], text)\n",
        "\n",
        "    # Handle newlines - simple approach: treat double newline as paragraph break\n",
        "    # Treat single newline as just a space unless we want explicit line breaks (\\\\)\n",
        "    text = text.replace('\\n\\n', '\\n\\n\\\\par\\n\\n') # Double newline -> paragraph\n",
        "    text = text.replace('\\n', ' ') # Single newline -> space (adjust if you want \\\\)\n",
        "\n",
        "    # Basic handling for bullet points (assuming '*' or '-' at start of line)\n",
        "    # This is simplistic and might need refinement\n",
        "    lines = text.splitlines()\n",
        "    processed_lines = []\n",
        "    in_itemize = False\n",
        "    for line in lines:\n",
        "         stripped_line = line.strip()\n",
        "         if stripped_line.startswith('* ') or stripped_line.startswith('- '):\n",
        "              item_content = stripped_line[2:].strip()\n",
        "              if item_content: # Only add if there's content after bullet\n",
        "                   if not in_itemize:\n",
        "                        processed_lines.append(r'\\begin{itemize}')\n",
        "                        in_itemize = True\n",
        "                   processed_lines.append(rf'  \\item {item_content}')\n",
        "         else:\n",
        "              if in_itemize:\n",
        "                   processed_lines.append(r'\\end{itemize}')\n",
        "                   in_itemize = False\n",
        "              processed_lines.append(line) # Add non-bullet lines (already escaped)\n",
        "    if in_itemize: # Close itemize if it was the last thing\n",
        "        processed_lines.append(r'\\end{itemize}')\n",
        "\n",
        "    return '\\n'.join(processed_lines)\n",
        "\n",
        "print(\"LaTeX escaping helper function defined.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:07:09.427743Z",
          "iopub.execute_input": "2025-04-20T18:07:09.428101Z",
          "iopub.status.idle": "2025-04-20T18:07:09.439764Z",
          "shell.execute_reply.started": "2025-04-20T18:07:09.428079Z",
          "shell.execute_reply": "2025-04-20T18:07:09.438667Z"
        },
        "id": "HuA_e24Pm75f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Latex CV Template:"
      ],
      "metadata": {
        "id": "zbde5QTGm75f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define Specific LaTeX CV Template (Provided by User) ---\n",
        "\n",
        "latex_template = r\"\"\"\n",
        "\\documentclass[11pt,a4paper]{article}\n",
        "\\usepackage[margin=0.6in]{geometry}\n",
        "\\usepackage{enumitem}\n",
        "\\usepackage{titlesec}\n",
        "\\usepackage[hidelinks]{hyperref}\n",
        "\\usepackage{parskip}\n",
        "\n",
        "% Define custom section formatting\n",
        "\\titleformat{\\section}{\\large\\bfseries}{}{0em}{}[\\titlerule]\n",
        "\\titleformat{\\subsection}{\\normalsize\\bfseries}{}{0em}{}\n",
        "\n",
        "\\begin{document}\n",
        "\n",
        "\\begin{center}\n",
        "    {\\LARGE \\textbf{Aida Afshar Nia}}\\\\[0.2cm]  % <<< --- Placeholder/Extractable\n",
        "    Calgary, AB \\quad $|$ \\quad +1~587-594-7668 \\quad $|$ \\quad \\href{mailto:aidaafsharnia@gmail.com}{aidaafsharnia@gmail.com} \\quad $|$ \\quad \\href{http://www.linkedin.com/in/aida-afsharnia-507274121/}{LinkedIn} % <<< --- Placeholder/Extractable\n",
        "\\end{center}\n",
        "\n",
        "\\vspace{0.3cm}\n",
        "\n",
        "\\section*{Professional Summary}\n",
        "\\begin{itemize}[leftmargin=*]\n",
        "%%SUMMARY_ITEMS_PLACEHOLDER%%\n",
        "\\end{itemize}\n",
        "\n",
        "\\section*{Key Skills}\n",
        "\\begin{itemize}[leftmargin=*]\n",
        "%%SKILLS_ITEMS_PLACEHOLDER%%\n",
        "\\end{itemize}\n",
        "\n",
        "% --- Rest of the template remains unchanged (Experience, Education etc.) ---\n",
        "% --- We are only dynamically updating Summary and Skills items ---\n",
        "\n",
        "\\section*{Professional Experience}\n",
        "\n",
        "\\textbf{Software Engineer at \\textit{Exro Technologies Inc.} } \\hfill \\textit{Sep 2022 -- Present}\n",
        "\\begin{itemize}[leftmargin=*]\n",
        "    \\item Developed and maintained a suite of microservices for a Linux-based, single-core system covering everything from U-Boot and kernel customizations to high-level application logic in Python and C/C++.\n",
        "    \\item Designed a custom IPC core module using ZeroMQ that listens for incoming messages and redirects them based on a custom protocol, supporting both JSON and binary payloads.\n",
        "    \\item Implemented local data conversion/management using Protocol Buffers following SunSpec standards.\n",
        "    \\item Implemented microservices using Python libraries (Flask, schedule, SQLite) and object-oriented C/C++ designs to ensure organized, maintainable code.\n",
        "    \\item Established CI/CD pipelines with Docker and Git, automating testing and enabling seamless release and package management.\n",
        "    \\item Integrated AWS services (S3, IoT) for secure data transfer to web dashboards, and implemented communication via MQTT and TCP.\n",
        "    \\item Developed key microservices including a 2030.5 client, OffGrid Controller, Modbus client/server, RS485 interface, AWS handler, remote SSH access, and AWS command/job management service.\n",
        "    \\item Built automated monitoring systems to track microservice PIDs, CPU/RAM usage, and system responsiveness, ensuring high reliability in real-time testing.\n",
        "    \\item Contributed to full-stack development by building web servers in C++ and Python and developing dynamic client interfaces using JavaScript, HTML, PHP, CSS, and Ninja.\n",
        "    \\item Diagnosed and resolved issues related to inter-service communication, database interactions, and real-time data handling using tools such as oscilloscopes, logic analyzers, and log monitoring.\n",
        "    \\item Conducted performance optimization by monitoring and profiling microservices to analyze system bottlenecks, applying optimizations to reduce latency and improve resource utilization.\n",
        "    \\item Addressed real-time data handling challenges by implementing asynchronous processing and message queues, and solved scalability issues through optimized database queries and load balancing strategies.\n",
        "\\end{itemize}\n",
        "\n",
        "\\textbf{Research Assistant at \\textit{Power Electronics Laboratory}} \\hfill \\textit{Sep 2019 -- Aug 2022}\n",
        "\\begin{itemize}[leftmargin=*]\n",
        "    \\item Developed control algorithms and simulation models for renewable energy systems using MATLAB/Simulink and Psim.\n",
        "    \\item Implemented and validated software models to improve stability and fault tolerance in energy conversion systems.\n",
        "    \\item Collaborated on hardware-in-loop testing setups, contributing to the integration of real-time monitoring and control software.\n",
        "\\end{itemize}\n",
        "\n",
        "\\textbf{Teacher Assistant \\& Laboratory Instructor at \\textit{University of Alberta}} \\hfill \\textit{Sep 2019 -- May 2022}\n",
        "\\begin{itemize}[leftmargin=*]\n",
        "    \\item Instructed over 200 students in Embedded System Design, Computer Interfacing, and Microprocessor fundamentals.\n",
        "    \\item Developed course projects and labs emphasizing C programming, assembly language, and real-time system debugging on STM microcontrollers.\n",
        "\\end{itemize}\n",
        "\n",
        "\\textbf{Research Assistant \\& Web Development at \\textit{Cognitive and Robotics Lab.}} \\hfill \\textit{Summer 2016--2019}\n",
        "\\begin{itemize}[leftmargin=*]\n",
        "    \\item Designed control and simulation projects for robotics, including data analysis for a rehabilitation device and NAO robot control using Microsoft Kinect.\n",
        "    \\item Developed web-based interfaces and databases (MySQL, PHP) to facilitate remote data acquisition and system monitoring.\n",
        "    \\item Integrated Wi-Fi modules (ESP8266) for real-time sensor data collection and remote system control.\n",
        "\\end{itemize}\n",
        "\n",
        "\\section*{Education}\n",
        "\\textbf{M.Sc. in Energy Systems}\\\\\n",
        "University of Alberta, Edmonton, Canada \\hfill \\textit{Sep 2019 -- Aug 2022}\n",
        "\n",
        "\\vspace{0.2cm}\n",
        "\n",
        "\\textbf{B.Sc. in Control Engineering}\\\\\n",
        "University of Tehran, Tehran \\hfill \\textit{Sep 2013 -- Jan 2018}\n",
        "\n",
        "\\section*{Publications}\n",
        "\\begin{itemize}[leftmargin=*]\n",
        "    \\item \\textit{Weighted Dynamic Aggregation Modeling of Induction Machine-Based Wind Farms}\n",
        "    \\item \\textit{Weighted Dynamic Aggregation Modeling of DC Microgrid Converters with Droop Control}\n",
        "    \\item \\textit{Droop-Based DC Microgrids Analysis and Control Design Using a Weighted Dynamic Aggregation Modeling Approach}\n",
        "\\end{itemize}\n",
        "\n",
        "\\section*{References}\n",
        "Available upon request.\n",
        "\n",
        "\\end{document}\n",
        "\"\"\"\n",
        "# Add placeholders inside the itemize environments\n",
        "latex_template = latex_template.replace(r\"\"\"    \\item Software Engineer with over 5 years of experience designing and implementing complex software systems on Linux-based platforms or embedded devices.\n",
        " \\item Proven expertise in developing microservices—from low-level bootloaders and kernel modifications to high-level Python and C/C++ services—ensuring robust system performance and scalability.\n",
        " \\item Skilled in architecting distributed systems with custom IPC mechanisms (using ZeroMQ) that enforce strict message protocols to guarantee integrity and timely responses.\n",
        " \\item Experienced in containerization (Docker), virtualization (QEMU), CI/CD automation via Git, and full-stack web development.\n",
        " \\item Demonstrated ability to integrate cloud services (AWS S3, AWS IoT) and implement comprehensive monitoring, debugging, and release management processes.\"\"\", \"%%SUMMARY_ITEMS_PLACEHOLDER%%\", 1)\n",
        "\n",
        "latex_template = latex_template.replace(r\"\"\"    \\item \\textbf{Software Development:} C, C++, Python; class-based design with signal/function inter-class communication.\n",
        " \\item \\textbf{Microservices \\& IPC:} Flask, schedule, ZeroMQ, RESTful service design, SQLite.\n",
        " \\item \\textbf{Containerization \\& CI/CD:} Docker, Git-based CI/CD pipelines for automated testing, package management, and release versioning.\n",
        " \\item \\textbf{Cloud Integration:} AWS S3, AWS IoT services; secure data transfer and remote management.\n",
        " \\item \\textbf{System Monitoring \\& Debugging:} Automated PID, CPU, and RAM monitoring; hardware-in-loop testing and core dump analysis.\n",
        " \\item \\textbf{Web Development:} Server-side development (C++/Python) and front-end skills (JavaScript, HTML, PHP, CSS, Ninja).\n",
        " \\item \\textbf{Additional Technologies:} MQTT, TCP , UART, CAN communication; currently learning Rust.\"\"\", \"%%SKILLS_ITEMS_PLACEHOLDER%%\", 1)\n",
        "\n",
        "\n",
        "print(\"Specific LaTeX CV template loaded with placeholders.\")\n",
        "# print(latex_template) # Optional: Print to verify placeholders"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:07:15.819308Z",
          "iopub.execute_input": "2025-04-20T18:07:15.819627Z",
          "iopub.status.idle": "2025-04-20T18:07:15.82914Z",
          "shell.execute_reply.started": "2025-04-20T18:07:15.819605Z",
          "shell.execute_reply": "2025-04-20T18:07:15.827815Z"
        },
        "id": "ZEGTcL0Im75f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Content and Populate Template:"
      ],
      "metadata": {
        "id": "cR-Q5K1Jm75f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Inputs:\n",
        "import os\n",
        "import subprocess\n",
        "import re\n",
        "from IPython.display import FileLink, display, HTML\n",
        "\n",
        "# --- Ensure necessary variables exist from previous steps ---\n",
        "if 'latex_template' not in locals() or not latex_template:\n",
        "    raise ValueError(\"Original LaTeX template is missing.\")\n",
        "if 'base_cv_text' not in locals() or not base_cv_text:\n",
        "    raise ValueError(\"Base CV text (from PDF/LLM) is missing.\")\n",
        "if 'extracted_info' not in locals() or not extracted_info:\n",
        "    extracted_info = {} # Provide empty dict if extraction failed\n",
        "    print(\"Warning: Job description info not fully extracted. LLM analysis may be limited.\")\n",
        "# We don't strictly need tailored_summary/skills_latex_items anymore, as the LLM will regenerate them\n",
        "\n",
        "# Prepare job info strings for the prompt\n",
        "job_skills_str = \", \".join(extracted_info.get('required_skills', [])) if extracted_info.get('required_skills') else \"Not specified\"\n",
        "job_resp_str = \"; \".join(extracted_info.get('key_responsibilities', [])) if extracted_info.get('key_responsibilities') else \"Not specified\"\n",
        "job_title_str = extracted_info.get('job_title', 'Not specified')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:07:19.649097Z",
          "iopub.execute_input": "2025-04-20T18:07:19.649399Z",
          "iopub.status.idle": "2025-04-20T18:07:19.655974Z",
          "shell.execute_reply.started": "2025-04-20T18:07:19.649377Z",
          "shell.execute_reply": "2025-04-20T18:07:19.654936Z"
        },
        "id": "s5KUgBQRm75f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Revised Prompt for Generating the Full Updated LaTeX Document ---\n",
        "# Adding explicit anti-hallucination constraint for experience and Adding Few-shots\n",
        "# Adding optimization instructions (prioritization, slight redundancy check)\n",
        "\n",
        "prompt_generate_full_latex_optimized = rf\"\"\"\n",
        "You are an expert LaTeX CV assistant. Your task is to generate a complete, updated LaTeX CV document based on the provided original template structure, original CV text context, and target job description details, adhering strictly to the modification rules.\n",
        "\n",
        "### TASK\n",
        "Generate a complete LaTeX document string as output, performing the following optimizations and updates:\n",
        "1.  **Tailor Content:** Update the Summary, Skills, and Experience sections to align with the Target Job Description.\n",
        "2.  **Prioritize Relevance:** Reorder items within the Key Skills section and put relevant skills text first within Professional Experience bullet points to emphasize qualifications matching the job description.\n",
        "3.  **Optimize Content (Cautiously):** While generating the updated text for Summary, Skills, and Experience, avoid significant redundancy. Do *not* remove entire sections from the original template structure.\n",
        "4.  **Maintain Originality:** Ensure all skills and experience details included are grounded in the 'Original Full CV Text'. **Do not add skills, experiences, or methodologies (like Agile/Scrum) if they are not present in the original CV text, even if mentioned in the job description.**\n",
        "5.  **Format Correctly:** Output strictly valid LaTeX code matching the original template's structure, starting *exactly* with `\\documentclass` and ending *exactly* with `\\end{{document}}`. # Escaped }} here\n",
        "\n",
        "### INPUTS\n",
        "\n",
        "1.  **Original LaTeX Template Structure:**\n",
        "    ```latex\n",
        "    {latex_template}\n",
        "    ```\n",
        "\n",
        "2.  **Original Full CV Text (for content reference):**\n",
        "    ```text\n",
        "    {base_cv_text[:10000]} # Limited length for context\n",
        "    ```\n",
        "\n",
        "3.  **Target Job Description Information:**\n",
        "    - Job Title: {job_title_str}\n",
        "    - Required Skills: {job_skills_str}\n",
        "    - Key Responsibilities: {job_resp_str}\n",
        "\n",
        "### EXAMPLE (Illustrates Prioritization/Highlighting)\n",
        "\n",
        "*   *Template Snippet:* ... (Same as before, ensure braces inside this example text are doubled too if needed, though usually not necessary inside ``` blocks) ...\n",
        "    ```latex\n",
        "    \\documentclass{{article}}  # Escaped {{ and }}\n",
        "    \\usepackage{{enumitem}}    # Escaped {{ and }}\n",
        "    \\begin{{document}}          # Escaped {{ and }}\n",
        "    \\section*{{Summary}}          # Escaped {{ and }}\n",
        "    \\begin{{itemize}}[leftmargin=*] # Escaped {{ and }}\n",
        "    \\item Generic point 1.\n",
        "    \\item Generic point 2.\n",
        "    \\end{{itemize}}             # Escaped {{ and }}\n",
        "    \\section*{{Skills}}           # Escaped {{ and }}\n",
        "    \\begin{{itemize}}[leftmargin=*] # Escaped {{ and }}\n",
        "    \\item \\textbf{{Dev:}} Python, C++ # Escaped {{ and }}\n",
        "    \\item \\textbf{{Tools:}} Git      # Escaped {{ and }}\n",
        "    \\end{{itemize}}             # Escaped {{ and }}\n",
        "    \\section*{{Experience}}       # Escaped {{ and }}\n",
        "    \\textbf{{Old Job}} \\hfill 2020-2021 # Escaped {{ and }}\n",
        "    \\begin{{itemize}}[leftmargin=*] # Escaped {{ and }}\n",
        "    \\item Developed web apps using \\textbf{{Python}}. # Escaped {{ and }}\n",
        "    \\item Used \\textbf{{Git}} for version control. # Escaped {{ and }}\n",
        "    \\end{{itemize}}             # Escaped {{ and }}\n",
        "    \\end{{document}}              # Escaped {{ and }}\n",
        "    ```\n",
        "*   *CV Context:* Software dev with Python, C++, Git experience. Built web apps. Experience includes \"Used Git for version control.\" and \"Developed web apps using Python.\"\n",
        "*   *Job Info:* Seeking Python Developer. Requires Python, Git. Responsibilities: Build backend services.\n",
        "*   *Expected Output Snippet (Focus on changes - braces inside this example also need escaping):*\n",
        "    ```latex\n",
        "    % ... preamble ...\n",
        "    \\section*{{Summary}}  # Escaped {{ and }}\n",
        "    \\begin{{itemize}}[leftmargin=*] # Escaped {{ and }}\n",
        "    \\item Software Developer highly proficient in \\textbf{{Python}} with experience in backend services. % Tailored & relevant skill emphasized # Escaped {{ and }}\n",
        "    \\item Skilled in version control using \\textbf{{Git}} and developing robust applications. % Tailored & relevant skill mentioned # Escaped {{ and }}\n",
        "    \\end{{itemize}}             # Escaped {{ and }}\n",
        "    \\section*{{Skills}}           # Escaped {{ and }}\n",
        "    \\begin{{itemize}}[leftmargin=*] # Escaped {{ and }}\n",
        "    \\item \\textbf{{Dev:}} Python, C++ # Escaped {{ and }}\n",
        "    \\item \\textbf{{Tools:}} Git      # Escaped {{ and }}\n",
        "    \\end{{itemize}}             # Escaped {{ and }}\n",
        "    \\section*{{Experience}}       # Escaped {{ and }}\n",
        "    \\textbf{{Old Job}} \\hfill 2020-2021 # Escaped {{ and }}\n",
        "    \\begin{{itemize}}[leftmargin=*] # Escaped {{ and }}\n",
        "    \\item Developed web apps using \\textbf{{Python}}. % Highlighted relevant skill IN EXISTING text # Escaped {{ and }}\n",
        "    \\item Used \\textbf{{Git}} for version control. % Highlighted relevant skill IN EXISTING text # Escaped {{ and }}\n",
        "    \\end{{itemize}}             # Escaped {{ and }}\n",
        "    % ... rest of document ...\n",
        "    \\end{{document}}             # Escaped {{ and }}\n",
        "    ```\n",
        "*(End of Example)*\n",
        "\n",
        "### DETAILED INSTRUCTIONS (Apply to the main INPUTS provided above)\n",
        "\n",
        "1.  **Base Structure:** Use the full 'Original LaTeX Template Structure'.\n",
        "2.  **Output Format:** Respond with ONLY the LaTeX code, starting exactly with `\\documentclass` and ending exactly with `\\end{{document}}`. NO extra text, comments, or markdown. # Escaped }}\n",
        "3.  **Personal Information:** Retain as is from the template for now.\n",
        "4.  **Professional Summary:** Replace content inside `itemize`. Generate 3-5 concise `\\item` points tailored to the Job Description. Escape LaTeX characters.\n",
        "5.  **Key Skills:** Replace content inside `itemize`. Include ONLY skills from the Original CV Text. **Reorder the `\\item` list (or skills within categories) to place skills highly relevant to the Job Description first.** Maintain `\\textbf{{Category:}}` format if applicable. Do NOT add skills only from the job description. Escape LaTeX characters. # Escaped {{ and }}\n",
        "6.  **Professional Experience:** Replicate the structure and content from the Original CV Text. Do NOT add new bullet points or information not present originally. For each original `\\item`:\n",
        "    *   Compare its exact text to the Job Description.\n",
        "    *   If words/phrases *already present* directly match a required skill/responsibility, enclose only those existing words/phrases in `\\textbf{{highlighted text}}`. Apply highlighting judiciously. # Escaped {{ and }}\n",
        "    *   Ensure proper LaTeX escaping for the entire item.\n",
        "7.  **Other Sections:** Retain Education, Publications, References based on the original structure/content, ensuring correct LaTeX format.\n",
        "8.  **LaTeX Validity:** Ensure correct syntax (braces `{{}}`, backslashes `\\\\`, environments). # Escaped {{ and }}\n",
        "\n",
        "### FINAL OUTPUT (Generate the complete, optimized, and constrained LaTeX document now)\n",
        "\"\"\" # Prompt definition ends here\n",
        "\n",
        "\n",
        "# --- (The rest of the code block calling the LLM and processing the output remains the same) ---\n",
        "print(\"Requesting LLM to generate optimized LaTeX document (Few-Shot, Constrained, Prioritized)...\")\n",
        "# Use the new prompt variable name (it still holds the escaped string)\n",
        "generated_latex_code = generate_text_with_gemini(prompt_generate_full_latex_optimized, is_json_output=False)\n",
        "\n",
        "# --- More Robust Post-Processing/Validation (Keep this identical to previous step) ---\n",
        "# --- More Robust Post-Processing/Validation ---\n",
        "validated_latex_code = None\n",
        "raw_latex_output_filename = \"llm_raw_output_optimized.tex\" # Optional raw output file\n",
        "\n",
        "if generated_latex_code:\n",
        "    print(f\"LLM returned output (length {len(generated_latex_code)}). Processing...\")\n",
        "    # (Optional: Save raw output for debugging)\n",
        "    # try:\n",
        "    #     with open(raw_latex_output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    #         f.write(generated_latex_code)\n",
        "    #     print(f\"Saved raw LLM output to {raw_latex_output_filename}\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"Warning: Could not save raw LLM output: {e}\")\n",
        "\n",
        "    processed_code = generated_latex_code.strip()\n",
        "\n",
        "    # Remove potential markdown fences\n",
        "    if processed_code.startswith(\"```latex\"):\n",
        "        processed_code = processed_code[7:].strip()\n",
        "    elif processed_code.startswith(\"```\"):\n",
        "        processed_code = processed_code[3:].strip()\n",
        "    if processed_code.endswith(\"```\"):\n",
        "        processed_code = processed_code[:-3].strip()\n",
        "\n",
        "    # Find the start and end markers\n",
        "    start_marker = r\"\\documentclass\"\n",
        "    end_marker = r\"\\end{document}\"\n",
        "    start_index = processed_code.find(start_marker)\n",
        "    end_index = processed_code.rfind(end_marker) # Use rfind for the *last* end marker\n",
        "\n",
        "    if start_index != -1 and end_index != -1 and start_index < end_index:\n",
        "        # --- MODIFICATION START ---\n",
        "        # Extract the content *between* the markers\n",
        "        extracted_code = processed_code[start_index : end_index + len(end_marker)]\n",
        "        print(\"Successfully extracted content between \\\\documentclass and \\\\end{document}.\")\n",
        "\n",
        "        # Check for and warn about unexpected text, but don't fail validation because of it\n",
        "        leading_text = processed_code[:start_index].strip()\n",
        "        trailing_text = processed_code[end_index + len(end_marker):].strip()\n",
        "\n",
        "        if leading_text:\n",
        "            print(f\"Warning: Found unexpected text before \\\\documentclass: '{leading_text}' (Ignoring)\")\n",
        "        if trailing_text:\n",
        "            print(f\"Warning: Found unexpected text after \\\\end{{document}}: '{trailing_text}' (Ignoring)\") # Escaped }}\n",
        "\n",
        "        # Assign the *extracted* code as the validated code\n",
        "        validated_latex_code = extracted_code\n",
        "        # --- MODIFICATION END ---\n",
        "\n",
        "        # Optional: Apply final LaTeX escaping if needed (e.g., for '&')\n",
        "        # print(\"Applying final LaTeX escaping (if necessary)...\")\n",
        "        # validated_latex_code = validated_latex_code.replace('&', r'\\&')\n",
        "        # validated_latex_code = validated_latex_code.replace('%', r'\\%') # Example\n",
        "        # validated_latex_code = validated_latex_code.replace('_', r'\\_') # Example\n",
        "\n",
        "    else:\n",
        "        print(f\"Error: Could not reliably find '{start_marker}' and '{end_marker}' markers in the correct order in the processed output.\")\n",
        "        print(\"--- Processed Output Start (first 200 chars) ---\")\n",
        "        print(processed_code[:200])\n",
        "        print(\"--- Processed Output End (last 200 chars) ---\")\n",
        "        print(processed_code[-200:])\n",
        "        print(\"--- End Processed Output ---\")\n",
        "        validated_latex_code = None # Ensure it's None if markers not found\n",
        "\n",
        "else:\n",
        "    print(\"Error: LLM failed to generate any LaTeX code response.\")\n",
        "    validated_latex_code = None\n",
        "\n",
        "\n",
        "# --- Write to .tex file (This part remains the same) ---\n",
        "tex_filename = \"updated_cv_llm_generated_fewshot.tex\"\n",
        "if validated_latex_code:\n",
        "    try:\n",
        "        # Ensure the validated_latex_code starts correctly *now*\n",
        "        if not validated_latex_code.startswith(r\"\\documentclass\"):\n",
        "             print(f\"CRITICAL WARNING: Final code does not start with \\\\documentclass after processing! Check logic.\")\n",
        "             # Decide if you want to proceed or raise an error here\n",
        "\n",
        "        with open(tex_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(validated_latex_code)\n",
        "        print(f\"Successfully wrote validated LaTeX code to {tex_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing .tex file: {e}\")\n",
        "        tex_filename = None\n",
        "else:\n",
        "    print(\"Skipping .tex file writing due to failed generation or validation.\")\n",
        "    tex_filename = None"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:07:30.997363Z",
          "iopub.execute_input": "2025-04-20T18:07:30.997701Z",
          "iopub.status.idle": "2025-04-20T18:08:13.20983Z",
          "shell.execute_reply.started": "2025-04-20T18:07:30.997677Z",
          "shell.execute_reply": "2025-04-20T18:08:13.208792Z"
        },
        "id": "eikvapbOm75f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Seperate Skill Gap Analysis:"
      ],
      "metadata": {
        "id": "dQ76MHxjm75g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prompt for Skill Gap Analysis (Human Readable) ---\n",
        "# Use the same prompt as used in earlier steps for \"Document Understanding\"\n",
        "\n",
        "prompt_skill_gap_analysis = f\"\"\"\n",
        "Analyze the alignment between the candidate's original CV skills/experience and the required skills for the job.\n",
        "\n",
        "Candidate's Original CV Text (relevant parts):\n",
        "---\n",
        "Skills Section:\n",
        "{base_skills_section}\n",
        "\n",
        "Experience Section Snippet (for context):\n",
        "{base_cv_text[base_cv_text.find('Professional Experience'):][:1500]} # Limit length\n",
        "---\n",
        "\n",
        "Required Skills from Job Description:\n",
        "---\n",
        "{job_skills_str}\n",
        "---\n",
        "\n",
        "Task:\n",
        "1.  Identify which **Required Skills** seem to be **present** and demonstrated in the Candidate's CV text (Skills section or Experience).\n",
        "2.  Identify key **Required Skills** that appear to be **missing** or not explicitly mentioned in the Candidate's CV text.\n",
        "3.  Provide suggestions for the candidate regarding these missing skills (e.g., consider learning, highlight adjacent skills, or rephrase existing experience if applicable but not obvious).\n",
        "\n",
        "Present the analysis clearly in a human-readable format. Do not use LaTeX formatting here.\n",
        "Example Output Structure:\n",
        "Present Skills:\n",
        "  - Skill A (Mentioned in Skills Section/Experience)\n",
        "  - Skill B (Demonstrated in Project X)\n",
        "Missing Skills:\n",
        "  - Skill C\n",
        "  - Skill D\n",
        "Suggestions:\n",
        "  - Consider taking a course or project focused on Skill C as it appears important for this role.\n",
        "  - While Skill D is not explicitly listed, your experience with Tool Y might be partially relevant; consider mentioning Tool Y if applying.\n",
        "\n",
        "Analysis:\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nRequesting Skill Gap Analysis for human-readable suggestions...\")\n",
        "skill_gap_analysis_text = generate_text_with_gemini(prompt_skill_gap_analysis, is_json_output=False)\n",
        "\n",
        "print(\"\\n--- Skill Gap Analysis and Suggestions ---\")\n",
        "if skill_gap_analysis_text:\n",
        "    # Simple cleaning of potential leading/trailing whitespace\n",
        "    skill_gap_analysis_text = skill_gap_analysis_text.strip()\n",
        "    print(skill_gap_analysis_text)\n",
        "else:\n",
        "    print(\"Failed to generate skill gap analysis.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:08:24.445084Z",
          "iopub.execute_input": "2025-04-20T18:08:24.445524Z",
          "iopub.status.idle": "2025-04-20T18:09:01.043035Z",
          "shell.execute_reply.started": "2025-04-20T18:08:24.445492Z",
          "shell.execute_reply": "2025-04-20T18:09:01.042046Z"
        },
        "id": "WiCph05lm75g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile Latex to PDF:"
      ],
      "metadata": {
        "id": "uFeZ193gm75g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_latex(tex_file_path):\n",
        "    \"\"\"\n",
        "    Compiles the given .tex file to PDF using pdflatex.\n",
        "\n",
        "    Args:\n",
        "        tex_file_path (str): The path to the .tex file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (success: bool, log_content: str | None, error_message: str | None)\n",
        "               - success: True if compilation seems successful (exit code 0), False otherwise.\n",
        "               - log_content: The content of the log file if generated.\n",
        "               - error_message: A specific error message if subprocess fails badly.\n",
        "    \"\"\"\n",
        "    if not tex_file_path or not os.path.exists(tex_file_path):\n",
        "        print(f\"Error: LaTeX file not found at '{tex_file_path}'\")\n",
        "        return False, None, f\"LaTeX file not found: {tex_file_path}\"\n",
        "\n",
        "    base_name = os.path.basename(tex_file_path).replace(\".tex\", \"\")\n",
        "    dir_name = os.path.dirname(tex_file_path) or '.'\n",
        "    pdf_file_path = os.path.join(dir_name, base_name + \".pdf\")\n",
        "    log_file_path = os.path.join(dir_name, base_name + \".log\")\n",
        "    compilation_success = False\n",
        "    log_content = None\n",
        "    error_message = None\n",
        "    last_return_code = -99 # Initialize with a distinct value\n",
        "\n",
        "    # Clean previous log before attempting compilation\n",
        "    if os.path.exists(log_file_path):\n",
        "        try:\n",
        "            os.remove(log_file_path)\n",
        "        except OSError as e:\n",
        "            print(f\"Warning: Could not remove previous log file '{log_file_path}': {e}\")\n",
        "\n",
        "    print(f\"\\nAttempting to compile {os.path.basename(tex_file_path)}...\")\n",
        "    # Run pdflatex twice for references etc. Use -halt-on-error for cleaner logs on failure.\n",
        "    for i in range(2):\n",
        "        print(f\"Running pdflatex compilation (Pass {i+1}/2)...\")\n",
        "        try:\n",
        "            process = subprocess.run(\n",
        "                ['pdflatex', '-interaction=nonstopmode', '-halt-on-error', tex_file_path],\n",
        "                capture_output=True, text=True, check=False, timeout=180, # Increased timeout\n",
        "                cwd=dir_name\n",
        "            )\n",
        "            last_return_code = process.returncode\n",
        "            if process.returncode != 0:\n",
        "                print(f\"Compilation failed on pass {i+1} with exit code {process.returncode}.\")\n",
        "                error_message = f\"pdflatex failed on pass {i+1} (exit code {process.returncode})\"\n",
        "                break # Stop if a pass fails\n",
        "        except subprocess.TimeoutExpired:\n",
        "             print(f\"Error: pdflatex timed out on pass {i+1}.\")\n",
        "             error_message = \"pdflatex timed out\"\n",
        "             last_return_code = -2 # Indicate timeout\n",
        "             break\n",
        "        except FileNotFoundError:\n",
        "             print(\"Error: 'pdflatex' command not found. Is LaTeX installed in the environment?\")\n",
        "             error_message = \"'pdflatex' command not found. Ensure TeX Live is installed.\"\n",
        "             last_return_code = -4 # Indicate command not found\n",
        "             break\n",
        "        except Exception as e:\n",
        "             print(f\"Error running pdflatex subprocess on pass {i+1}: {e}\")\n",
        "             error_message = f\"Subprocess error: {e}\"\n",
        "             last_return_code = -3 # Indicate other subprocess error\n",
        "             break\n",
        "\n",
        "    # Read log file regardless of exit code, as it might contain useful info\n",
        "    try:\n",
        "        if os.path.exists(log_file_path):\n",
        "            with open(log_file_path, 'r', encoding='utf-8', errors='ignore') as log_file:\n",
        "                log_content = log_file.read()\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not read log file '{log_file_path}': {e}\")\n",
        "        if not error_message: error_message = f\"Failed to read log file: {e}\"\n",
        "\n",
        "\n",
        "    # Check final results\n",
        "    # Success requires exit code 0 AND the PDF file to exist\n",
        "    if last_return_code == 0 and os.path.exists(pdf_file_path):\n",
        "        print(f\"Successfully compiled {os.path.basename(tex_file_path)} to {os.path.basename(pdf_file_path)}\")\n",
        "        compilation_success = True\n",
        "    else:\n",
        "        print(f\"Error during LaTeX compilation (Last exit code {last_return_code}).\")\n",
        "        if log_content:\n",
        "            error_lines = [line for line in log_content.splitlines() if line.startswith('! ')]\n",
        "            if error_lines:\n",
        "                print(\"\\nPotential Error lines found in log:\")\n",
        "                for line in error_lines[:10]: print(line) # Limit output\n",
        "                display(HTML(f\"<p style='color:red;'>LaTeX compilation failed. Check '{os.path.basename(log_file_path)}' or errors above.</p>\"))\n",
        "            else:\n",
        "                 print(\"\\nNo lines starting with '! ' found in log. Check full log for errors or warnings.\")\n",
        "                 display(HTML(f\"<p style='color:orange;'>LaTeX compilation failed (Exit code: {last_return_code}). PDF may not exist or be complete. Check '{os.path.basename(log_file_path)}'.</p>\"))\n",
        "        else:\n",
        "            display(HTML(f\"<p style='color:red;'>LaTeX compilation failed. Log file could not be read. Error: {error_message}</p>\"))\n",
        "\n",
        "    return compilation_success, log_content, error_message"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:22:06.658847Z",
          "iopub.execute_input": "2025-04-20T18:22:06.659217Z",
          "iopub.status.idle": "2025-04-20T18:22:06.674192Z",
          "shell.execute_reply.started": "2025-04-20T18:22:06.659191Z",
          "shell.execute_reply": "2025-04-20T18:22:06.673053Z"
        },
        "id": "ID90iyWRm75g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Compile LaTeX to PDF ---\n",
        "pdf_filename = \"updated_cv_llm_generated_fewshot.tex\"\n",
        "compilation_success = False\n",
        "\n",
        "\n",
        "pdf_filename = tex_filename.replace(\".tex\", \".pdf\") # Derive PDF name\n",
        "log_filename = tex_filename.replace(\".tex\", \".log\") # Derive LOG name\n",
        "\n",
        "# Check if the CORRECT tex file exists before trying to compile\n",
        "if tex_filename and os.path.exists(tex_filename):\n",
        "    print(f\"\\nAttempting to compile {tex_filename} to PDF...\") # Should print the ...escaped.tex name\n",
        "    # Run pdflatex twice\n",
        "    for i in range(2):\n",
        "        print(f\"Running pdflatex compilation (Pass {i+1}/2)...\")\n",
        "        process = subprocess.run(\n",
        "            ['pdflatex', '-interaction=nonstopmode', tex_filename], # Uses the correct filename\n",
        "            capture_output=True, text=True, check=False, timeout=120\n",
        "        )\n",
        "        if process.returncode != 0:\n",
        "            print(f\"Compilation failed on pass {i+1} with exit code {process.returncode}.\")\n",
        "            break\n",
        "\n",
        "    # Check final results (uses correct pdf_filename)\n",
        "    if process.returncode == 0 and os.path.exists(pdf_filename):\n",
        "        print(f\"Successfully compiled {tex_filename} to {pdf_filename}\")\n",
        "        compilation_success = True\n",
        "        display(HTML(f\"<p style='color:green;'>Successfully generated {pdf_filename}.</p>\"))\n",
        "    else:\n",
        "        print(f\"Error during LaTeX compilation (Last exit code {process.returncode}).\")\n",
        "        # Uses correct log_filename\n",
        "        display(HTML(f\"<p style='color:red;'>LaTeX compilation failed. Check '{log_filename}' for details.</p>\"))\n",
        "        # Print log snippet (Uses correct log_filename)\n",
        "        try:\n",
        "            with open(log_filename, 'r', encoding='utf-8', errors='ignore') as log_file:\n",
        "                 # ... (rest of log reading code) ...\n",
        "                 log_content = log_file.read()\n",
        "                 error_lines = [line for line in log_content.splitlines() if line.startswith('! ')]\n",
        "                 if error_lines:\n",
        "                      print(\"Potential Error lines found:\")\n",
        "                      for line in error_lines[:10]: print(line)\n",
        "                 else:\n",
        "                      # ... (warning checks) ...\n",
        "                      print(\"No lines starting with '! ' found, check full log.\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Could not find log file: {log_filename}\") # Will print correct name now\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading log file: {e}\")\n",
        "else:\n",
        "    # This message should indicate if the expected .tex file wasn't found\n",
        "    print(f\"\\nSkipping compilation because the expected .tex file '{tex_filename}' was not found or not generated successfully.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:22:12.22423Z",
          "iopub.execute_input": "2025-04-20T18:22:12.224608Z",
          "iopub.status.idle": "2025-04-20T18:22:14.787899Z",
          "shell.execute_reply.started": "2025-04-20T18:22:12.224573Z",
          "shell.execute_reply": "2025-04-20T18:22:14.786729Z"
        },
        "id": "8jxGBvaRm75g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Provide Download Link:\n"
      ],
      "metadata": {
        "id": "-9nVkzkbm75h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Display Skill Suggestions and Provide Download Link ---\n",
        "\n",
        "print(\"\\n\" + \"=\"*30 + \" Suggestions Based on Skill Gap Analysis \" + \"=\"*30)\n",
        "if skill_gap_analysis_text:\n",
        "    print(skill_gap_analysis_text)\n",
        "else:\n",
        "    print(\"Skill gap analysis was not generated.\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "if compilation_success and os.path.exists(pdf_filename):\n",
        "    print(f\"\\nDownload the updated CV PDF (LLM Generated):\")\n",
        "    display(FileLink(pdf_filename))\n",
        "else:\n",
        "    print(f\"\\nCould not generate {pdf_filename}.\")\n",
        "    if tex_filename and os.path.exists(tex_filename):\n",
        "         print(f\"You can download the generated .tex file for manual debugging:\")\n",
        "         display(FileLink(tex_filename))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:22:19.242778Z",
          "iopub.execute_input": "2025-04-20T18:22:19.24313Z",
          "iopub.status.idle": "2025-04-20T18:22:19.252153Z",
          "shell.execute_reply.started": "2025-04-20T18:22:19.243105Z",
          "shell.execute_reply": "2025-04-20T18:22:19.251245Z"
        },
        "id": "tCghB0g3m75h"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output Evaluation:"
      ],
      "metadata": {
        "id": "ztBRzxGAm75h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Proposed CV Updates & Analysis\n",
        "# --- Step 3a: Evaluate Generated CV Content Against Job Description ---\n",
        "\n",
        "evaluation_rating = None\n",
        "evaluation_justification = None\n",
        "\n",
        "# Only proceed if we have validated LaTeX code and extracted job info\n",
        "if validated_latex_code and extracted_info:\n",
        "    print(\"\\n\" + \"=\"*30 + \" Evaluating Generated CV Fit \" + \"=\"*30)\n",
        "\n",
        "    # Prepare concise job info for the evaluation prompt\n",
        "    eval_job_skills = extracted_info.get('required_skills', [])\n",
        "    eval_job_resp = extracted_info.get('key_responsibilities', [])\n",
        "    eval_job_title = extracted_info.get('job_title', 'N/A')\n",
        "\n",
        "    if not eval_job_skills and not eval_job_resp:\n",
        "        print(\"Warning: Insufficient job description details extracted for a meaningful evaluation.\")\n",
        "    else:\n",
        "        # Limit the LaTeX code sent for evaluation to avoid excessive length, focus on key sections\n",
        "        # Find start of summary and end of experience (approximate - adjust regex if needed)\n",
        "        summary_start_match = re.search(r\"\\\\section\\*\\{Professional Summary\\}\", validated_latex_code, re.IGNORECASE)\n",
        "        experience_end_match = re.search(r\"\\\\section\\*\\{Education\\}\", validated_latex_code, re.IGNORECASE)\n",
        "\n",
        "        cv_content_for_eval = validated_latex_code # Default to full code\n",
        "        if summary_start_match and experience_end_match:\n",
        "             start_idx = summary_start_match.start()\n",
        "             end_idx = experience_end_match.start()\n",
        "             cv_content_for_eval = validated_latex_code[start_idx:end_idx]\n",
        "             print(\"Evaluating content from Summary through Experience sections...\")\n",
        "        elif summary_start_match:\n",
        "             cv_content_for_eval = validated_latex_code[summary_start_match.start():] # Eval from summary onwards\n",
        "             print(\"Evaluating content from Summary section onwards...\")\n",
        "        else:\n",
        "             print(\"Warning: Could not isolate key sections. Evaluating first 10000 chars of generated LaTeX.\")\n",
        "             cv_content_for_eval = validated_latex_code[:10000]\n",
        "\n",
        "\n",
        "        prompt_evaluate_cv = rf\"\"\"\n",
        "        You are an expert Technical Recruiter evaluating a candidate's CV against a specific job description.\n",
        "\n",
        "        **Inputs:**\n",
        "\n",
        "        1.  **Candidate CV Content (Extracted from generated LaTeX - focus on text content, ignore syntax):**\n",
        "            ```latex\n",
        "            {cv_content_for_eval}\n",
        "            ```\n",
        "\n",
        "        2.  **Target Job Description:**\n",
        "            - Title: {eval_job_title}\n",
        "            - Required Skills: {', '.join(eval_job_skills) if eval_job_skills else 'Not specified'}\n",
        "            - Key Responsibilities: {'; '.join(eval_job_resp) if eval_job_resp else 'Not specified'}\n",
        "\n",
        "        **Evaluation Task:**\n",
        "\n",
        "        Assess how well the provided Candidate CV Content aligns with the Target Job Description. Consider the following:\n",
        "        - **Summary Relevance:** Does the summary effectively highlight experience relevant to the job title and responsibilities?\n",
        "        - **Skill Alignment:** Does the CV showcase the required skills prominently? Are the listed skills relevant?\n",
        "        - **Experience Match:** Do the experience descriptions (especially any highlighted parts) demonstrate capabilities relevant to the job's key responsibilities and required skills?\n",
        "        - **Overall Fit:** Based *only* on the provided texts, how strong is the match between the CV and the job?\n",
        "\n",
        "        **Output Format:**\n",
        "\n",
        "        Respond ONLY with a valid JSON object containing two keys:\n",
        "        1.  `rating`: An integer score from 1 to 5, representing the overall fit.\n",
        "        2.  `justification`: A brief text explanation (2-4 sentences) justifying the rating, mentioning specific strengths or weaknesses regarding the job fit.\n",
        "\n",
        "        **Rating Scale:**\n",
        "        - 1: Poor Fit (Very few relevant skills/experience)\n",
        "        - 2: Weak Fit (Some overlap, but major gaps)\n",
        "        - 3: Moderate Fit (Reasonable match for several requirements, some gaps remain)\n",
        "        - 4: Strong Fit (Good alignment with most key requirements)\n",
        "        - 5: Excellent Fit (Very strong alignment, clearly demonstrates suitability for key skills/responsibilities)\n",
        "\n",
        "        **JSON Output:**\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"Requesting LLM to evaluate CV fit...\")\n",
        "        evaluation_response_str = generate_text_with_gemini(prompt_evaluate_cv, is_json_output=True)\n",
        "\n",
        "        if evaluation_response_str:\n",
        "            try:\n",
        "                # Clean potential markdown fences\n",
        "                if evaluation_response_str.strip().startswith(\"```json\"):\n",
        "                    evaluation_response_str = evaluation_response_str.strip()[7:-3].strip()\n",
        "                elif evaluation_response_str.strip().startswith(\"```\"):\n",
        "                     evaluation_response_str = evaluation_response_str.strip()[3:-3].strip()\n",
        "\n",
        "                evaluation_result = json.loads(evaluation_response_str)\n",
        "\n",
        "                rating = evaluation_result.get('rating')\n",
        "                justification = evaluation_result.get('justification')\n",
        "\n",
        "                # Basic validation of rating\n",
        "                if isinstance(rating, int) and 1 <= rating <= 5:\n",
        "                    evaluation_rating = rating\n",
        "                    print(f\"Evaluation Rating: {evaluation_rating}/5\")\n",
        "                else:\n",
        "                    print(f\"Warning: Received invalid rating value: {rating}\")\n",
        "\n",
        "                if isinstance(justification, str) and justification.strip():\n",
        "                    evaluation_justification = justification.strip()\n",
        "                    print(f\"Justification: {evaluation_justification}\")\n",
        "                else:\n",
        "                    print(\"Warning: Received invalid or empty justification.\")\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error parsing JSON response from evaluation LLM: {e}\")\n",
        "                print(\"Raw Response Snippet:\", evaluation_response_str[:500])\n",
        "            except Exception as e:\n",
        "                print(f\"An unexpected error occurred processing the evaluation response: {e}\")\n",
        "                print(\"Raw Response Snippet:\", evaluation_response_str[:500])\n",
        "        else:\n",
        "            print(\"LLM evaluation call failed or returned no response.\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping CV Evaluation step because generated LaTeX code or job info is missing.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*30 + \" Final Results & Downloads \" + \"=\"*30)\n",
        "\n",
        "# Display Evaluation Results\n",
        "print(\"\\n--- Generated CV Evaluation ---\")\n",
        "if evaluation_rating is not None:\n",
        "    print(f\"Rating vs. Job Description: {evaluation_rating}/5\")\n",
        "    print(f\"Justification: {evaluation_justification if evaluation_justification else 'N/A'}\")\n",
        "else:\n",
        "    print(\"Evaluation could not be completed.\")\n",
        "\n",
        "# Display Skill Suggestions\n",
        "print(\"\\n--- Skill Gap Analysis & Suggestions ---\")\n",
        "if 'skill_gap_analysis_text' in locals() and skill_gap_analysis_text:\n",
        "    print(skill_gap_analysis_text)\n",
        "else:\n",
        "    print(\"Skill gap analysis was not generated or failed.\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Display Download Links\n",
        "if compilation_success and os.path.exists(pdf_filename):\n",
        "    print(f\"\\nDownload the updated CV PDF:\")\n",
        "    display(FileLink(pdf_filename))\n",
        "else:\n",
        "    print(f\"\\nCould not generate {pdf_filename}.\")\n",
        "    if tex_filename and os.path.exists(tex_filename):\n",
        "        print(f\"You can download the generated .tex file for manual debugging:\")\n",
        "        display(FileLink(tex_filename))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-20T18:22:30.854967Z",
          "iopub.execute_input": "2025-04-20T18:22:30.856121Z",
          "iopub.status.idle": "2025-04-20T18:22:51.178836Z",
          "shell.execute_reply.started": "2025-04-20T18:22:30.856074Z",
          "shell.execute_reply": "2025-04-20T18:22:51.177302Z"
        },
        "id": "ooEj1p1ym75h"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limitation and future work:"
      ],
      "metadata": {
        "id": "5RUJYc1Jm75i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion\n",
        "\n",
        "**GenAI Capabilities Demonstrated:**\n",
        "\n",
        "1.  **Structured Output (JSON):** Used the Gemini API's capability (or instructed via prompt) to return extracted job details in JSON format, enabling easier programmatic use (Phase 4, Step 9).\n",
        "2.  **Few-Shot Prompting:** Provided examples within the prompt to guide the model in generating a high-quality, relevant tailored CV summary, improving upon zero-shot results (Phase 4, Step 10).\n",
        "3.  **Document Understanding:** Leveraged the model's ability to read, comprehend, and compare information from two distinct text sources (CV and Job Description analysis) to perform skill matching and gap analysis (Phase 4, Step 11).\n",
        "\n",
        "**Limitations:**\n",
        "*   **Web Scraping Fragility:** Still a major dependency. LinkedIn, Greenhouse, etc., often change layouts or use JavaScript, making scraping unreliable without more advanced tools (like Selenium).\n",
        "*   **API Dependency & Cost:** Relies on Google API access and may incur costs. Subject to rate limits or outages.\n",
        "*   **Model Interpretation:** The model's understanding of \"skill match\" or \"relevance\" might differ from human interpretation. Output requires review.\n",
        "*   **Context Window Limits:** While Gemini models have large context windows, extremely long CVs or job posts might still exceed limits (though less likely than with smaller models). We truncated the JD input as a precaution.\n",
        "*   **Safety Filters:** Overly strict safety settings might block legitimate responses, while lax settings risk inappropriate content (though less likely for this use case).\n",
        "*   **JSON Mode Reliability:** If `response_mime_type` isn't perfectly supported or the model deviates, JSON parsing can fail. The fallback instruction helps but isn't foolproof.\n",
        "\n",
        "**Creativity & Problem Solving:**\n",
        "*   Combined web scraping, structured data extraction, and multiple prompting techniques (few-shot, instruction-based) using the Gemini API.\n",
        "*   Implemented specific GenAI capabilities (Structured Output, Few-Shot, Document Understanding) relevant to the course objectives.\n",
        "*   Included basic error handling for API calls and JSON parsing.\n",
        "\n",
        "**Future Work:**\n",
        "*   **Implement RAG:** Use embeddings (e.g., Google's embedding models via API or local Sentence Transformers) and vector search (FAISS, ChromaDB) to find the *most* relevant CV sections for *each* job requirement before generation – this would be a major enhancement demonstrating Embeddings, Vector Search, and RAG.\n",
        "*   **Fine-tunning:** Fine tune a smaller model specifically on CV/Job Description data (more advanced).\n",
        "*   **Refine Scraping:** Use `Selenium` (harder in Kaggle) or specific API scraping services for job boards if available. Add more robust parsing logic for common job sites.\n",
        "*   **Bullet Point Generation:** Add a step to rewrite specific experience bullet points using keywords/responsibilities from the job description.\n",
        "*   **User Interface:** Build a simple UI using Gradio/Streamlit (might require running outside Kaggle or using specific integrations).\n",
        "*   **Evaluation Metric:** Implement a simple GenAI evaluation (e.g., ask Gemini to rate the generated summary's relevance to the job description on a scale of 1-5, using another prompt).\n",
        "*   **Agent Framework:** Re-structure the workflow using an agent framework (like LangChain with Gemini integration) where the agent decides the sequence of actions (scrape, extract, compare, rewrite)."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-15T18:21:20.575842Z",
          "iopub.execute_input": "2025-04-15T18:21:20.576278Z",
          "iopub.status.idle": "2025-04-15T18:21:20.589632Z",
          "shell.execute_reply.started": "2025-04-15T18:21:20.576247Z",
          "shell.execute_reply": "2025-04-15T18:21:20.588318Z"
        },
        "id": "-IRa_azzm75i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EYhtg4Jjm75j"
      }
    }
  ]
}